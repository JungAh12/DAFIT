import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers import Flatten
from keras.preprocessing.image import ImageDataGenerator

train_size = 10233
val_size = 200
test_size = 200
batch_size = 32
np.random.seed(3)

#데이터 생성
train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory('.\\train', target_size=(50,50), batch_size=batch_size, class_mode='categorical')

val_datagen = ImageDataGenerator(rescale=1./255)
val_generator = val_datagen.flow_from_directory('.\\val', target_size=(50,50), batch_size=batch_size, class_mode='categorical')

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = val_datagen.flow_from_directory('.\\test', target_size=(50,50), batch_size=batch_size, class_mode='categorical')

model = Sequential()
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(50,50,3)))
model.add(MaxPooling2D((2,2)))
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(3, activation='softmax'))

#모델 학습
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
hist = model.fit(train_generator, steps_per_epoch=train_size/batch_size, epochs=50, validation_data=val_generator, validation_steps=val_size/batch_size)

#모델 평가
print("--Evaluate--")
scores = model.evaluate(test_generator, steps=test_size/batch_size)
print("%s: %.2f%%" %(model.metrics_names[1], scores[1]*100))