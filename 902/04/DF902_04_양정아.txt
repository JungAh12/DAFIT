relu
0보다 크면 그 값을 그대로 쓰고 0보다 작으면 0을 사용하는 활성화 함수. max(0,x)
입력이 음수인 경우 계속 0이 되어 dying Relu 가 발생한다.

softmax
주로 output을 0~1 사이 값으로 정규화하여 주로 확률값으로 나타내는 경우에 사용하는 활성화 함수.