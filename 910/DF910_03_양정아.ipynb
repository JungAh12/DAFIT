{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DF910_03_양정아.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JAxfrI1mgWO_","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jhlyZKT3geXX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":325},"outputId":"b342acc7-4809-4a24-b09a-beb939464f78","executionInfo":{"status":"ok","timestamp":1576597310521,"user_tz":-540,"elapsed":9881,"user":{"displayName":"양갱","photoUrl":"","userId":"09896622485661166142"}}},"source":["trans = torchvision.transforms.Compose([\n","                                              torchvision.transforms.Normalize(0.5,0.5),\n","                                              torchvision.transforms.ToTensor()\n","])\n","\n","train_dataset = torchvision.datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, transform=trans)\n","val_dataset = torchvision.datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, transform=trans)\n","test_dataset = torchvision.datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=False, transform=trans)\n","\n","indices = list(range(len(train_dataset.train_data)))\n","split = int(len(indices)*0.2)\n","train_idx, val_idx = indices[:split], indices[split:]\n","\n","train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n","train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32, sampler=train_sampler)\n","val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_idx)\n","val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=32, sampler=val_sampler)\n","test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["26427392it [00:04, 5824239.25it/s]                              \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n"],"name":"stdout"},{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 40102.14it/s]                           \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["4423680it [00:02, 1689485.46it/s]                             \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 15013.75it/s]            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n","  warnings.warn(\"train_data has been renamed data\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"IhgiPeA_h9Gu","colab_type":"code","colab":{}},"source":["from torch import nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rb9Mm9lehaU6","colab_type":"code","colab":{}},"source":["class MLP1(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.fc2 = nn.Linear(256, 10)\n","    \n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)\n","        x = nn.functional.sigmoid(self.fc1(x))\n","        x = nn.functional.softmax(self.fc2(x),1)\n","\n","        return x\n","\n","class MLP2(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 10)\n","        \n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)\n","        x = nn.functional.sigmoid(self.fc1(x))\n","        x = nn.functional.sigmoid(self.fc2(x))\n","        x = nn.functional.softmax(self.fc3(x),1)\n","\n","        return x\n","\n","class MLP3(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 10)\n","        \n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)\n","        x = nn.functional.sigmoid(self.fc1(x))\n","        x = nn.functional.sigmoid(self.fc2(x))\n","        x = nn.functional.sigmoid(self.fc3(x))\n","        x = nn.functional.softmax(self.fc4(x),1)\n","\n","        return x\n","\n","class MLP4(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.fc2 = nn.Linear(256, 10)\n","    \n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)\n","        x = nn.functional.relu(self.fc1(x))\n","        x = nn.functional.softmax(self.fc2(x),1)\n","\n","        return x\n","\n","class MLP5(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 10)\n","        \n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)\n","        x = nn.functional.relu(self.fc1(x))\n","        x = nn.functional.relu(self.fc2(x))\n","        x = nn.functional.softmax(self.fc3(x),1)\n","\n","        return x\n","\n","class MLP6(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 10)\n","        \n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)\n","        x = nn.functional.relu(self.fc1(x))\n","        x = nn.functional.relu(self.fc2(x))\n","        x = nn.functional.relu(self.fc3(x))\n","        x = nn.functional.softmax(self.fc4(x),1)\n","\n","        return x\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wq1O9HXTj9mL","colab_type":"code","colab":{}},"source":["from torchsummary import summary"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxb98KQGkeoN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"29f3acdc-e56c-4112-e4e5-42da8e7ba44b","executionInfo":{"status":"ok","timestamp":1576598218319,"user_tz":-540,"elapsed":816,"user":{"displayName":"양갱","photoUrl":"","userId":"09896622485661166142"}}},"source":["model = [MLP1(), MLP2(), MLP3(), MLP4(), MLP5(), MLP6()]\n","\n","for i in range(6):\n","    summary(model[i],(1,28,28))\n","    print(\"***********************************************\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 256]         200,960\n","            Linear-2                   [-1, 10]           2,570\n","================================================================\n","Total params: 203,530\n","Trainable params: 203,530\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.78\n","Estimated Total Size (MB): 0.78\n","----------------------------------------------------------------\n","***********************************************\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 256]         200,960\n","            Linear-2                  [-1, 128]          32,896\n","            Linear-3                   [-1, 10]           1,290\n","================================================================\n","Total params: 235,146\n","Trainable params: 235,146\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.90\n","Estimated Total Size (MB): 0.90\n","----------------------------------------------------------------\n","***********************************************\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 256]         200,960\n","            Linear-2                  [-1, 128]          32,896\n","            Linear-3                   [-1, 64]           8,256\n","            Linear-4                   [-1, 10]             650\n","================================================================\n","Total params: 242,762\n","Trainable params: 242,762\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.93\n","Estimated Total Size (MB): 0.93\n","----------------------------------------------------------------\n","***********************************************\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 256]         200,960\n","            Linear-2                   [-1, 10]           2,570\n","================================================================\n","Total params: 203,530\n","Trainable params: 203,530\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.78\n","Estimated Total Size (MB): 0.78\n","----------------------------------------------------------------\n","***********************************************\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 256]         200,960\n","            Linear-2                  [-1, 128]          32,896\n","            Linear-3                   [-1, 10]           1,290\n","================================================================\n","Total params: 235,146\n","Trainable params: 235,146\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.90\n","Estimated Total Size (MB): 0.90\n","----------------------------------------------------------------\n","***********************************************\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 256]         200,960\n","            Linear-2                  [-1, 128]          32,896\n","            Linear-3                   [-1, 64]           8,256\n","            Linear-4                   [-1, 10]             650\n","================================================================\n","Total params: 242,762\n","Trainable params: 242,762\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.93\n","Estimated Total Size (MB): 0.93\n","----------------------------------------------------------------\n","***********************************************\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"POE-LMAnkyJD","colab_type":"text"},"source":["#MLP 모델들의 가장 눈에 띄는 차이\n","1. 파라미터 수\n","2. 용량\n","\n","model layer가 너무 많아지면 overfitting이 발생한다.\n","그러나 너무 layer가 얕게 구성되어 있어도 underfitting이 발생하기 때문에 적당한 균형을 유지하는 것이 중요하다.\n","\n","\n","###sigmoid와 relu를 적용한 차이\n","\n","sigmoid는 gradient vanishing 문제로 layer를 지날 때 마다 작아진 값이 현저히 더 작아져서 backpropagation 과정에서 제대로 학습이 이루어지지 않는다.\n","sigmoid 함수의 모양을 보면 양 극단의 미분값이 0에 가까워지기 때문이다.\n","\n","이런 문제를 해결하고자\n","제프리 힌튼 교수님의 ReLU가 등장한다.\n","\n","$$\n","ReLU = max(0, x)\n","$$\n","\n","양수일 때 그대로 자신의 값을 유지하기 때문에 Gradient vanishing을 극복함."]}]}